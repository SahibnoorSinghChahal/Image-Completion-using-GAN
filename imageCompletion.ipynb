{
  "cells": [
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os\nimport imghdr\nimport numpy as np\nimport cv2\nfrom keras.models import Sequential, Model\nfrom keras.engine.network import Network\nfrom keras.utils import generic_utils\nfrom keras.layers import Reshape, Lambda, Conv2D, Conv2DTranspose, Flatten, Activation, Dense, Input\nfrom keras.optimizers import Adadelta\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import concatenate\nimport keras.backend as K\nimport tensorflow as tf\nimport matplotlib.pyplot as mplt",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def Generative(input_shape=(256, 256, 3)):\n    \n    model = Sequential()\n    model.add(Conv2D(64, kernel_size=5, strides=1, padding='same',dilation_rate=(1, 1), input_shape=input_shape))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(128, kernel_size=3, strides=1, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(256, kernel_size=3, strides=2, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', dilation_rate=(2, 2)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', dilation_rate=(4, 4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', dilation_rate=(8, 8)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', dilation_rate=(16, 16)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n\n    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(128, kernel_size=3, strides=1, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n\n    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, kernel_size=3, strides=1, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n\n    model.add(Conv2D(3, kernel_size=3, strides=1, padding='same', dilation_rate=(1, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('sigmoid'))\n    return model",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def Discriminative(global_shape=(256, 256, 3), local_shape=(128, 128, 3)):\n    def imgCrop(img, crop):\n        return tf.image.crop_to_bounding_box(img, crop[1], crop[0], crop[3] - crop[1], crop[2] - crop[0])\n\n    inputLayer = Input(shape=(4,), dtype='int32')\n    cropping = Lambda(lambda x: K.map_fn(lambda y: imgCrop(y[0], y[1]), elems=x, dtype=tf.float32), output_shape=local_shape)\n    g_img = Input(shape=global_shape)\n    l_img = cropping([g_img, inputLayer])\n\n    DisNetwork = Conv2D(64, kernel_size=5, strides=2, padding='same')(l_img)\n    DisNetwork = BatchNormalization()(DisNetwork)\n    DisNetwork = Activation('relu')(DisNetwork)\n    DisNetwork = Conv2D(128, kernel_size=5, strides=2, padding='same')(DisNetwork)\n    DisNetwork = BatchNormalization()(DisNetwork)\n    DisNetwork = Activation('relu')(DisNetwork)\n    DisNetwork = Conv2D(256, kernel_size=5, strides=2, padding='same')(DisNetwork)\n    DisNetwork = BatchNormalization()(DisNetwork)\n    DisNetwork = Activation('relu')(DisNetwork)\n    DisNetwork = Conv2D(512, kernel_size=5, strides=2, padding='same')(DisNetwork)\n    DisNetwork = BatchNormalization()(DisNetwork)\n    DisNetwork = Activation('relu')(DisNetwork)\n    DisNetwork = Conv2D(512, kernel_size=5, strides=2, padding='same')(DisNetwork)\n    DisNetwork = BatchNormalization()(DisNetwork)\n    DisNetwork = Activation('relu')(DisNetwork)\n    DisNetwork = Flatten()(DisNetwork)\n    DisNetwork = Dense(1024, activation='relu')(DisNetwork)\n\n    GenNetwork = Conv2D(64, kernel_size=5, strides=2, padding='same')(g_img)\n    GenNetwork = BatchNormalization()(GenNetwork)\n    GenNetwork = Activation('relu')(GenNetwork)\n    GenNetwork = Conv2D(128, kernel_size=5, strides=2, padding='same')(GenNetwork)\n    GenNetwork = BatchNormalization()(GenNetwork)\n    GenNetwork = Activation('relu')(GenNetwork)\n    GenNetwork = Conv2D(256, kernel_size=5, strides=2, padding='same')(GenNetwork)\n    GenNetwork = BatchNormalization()(GenNetwork)\n    GenNetwork = Activation('relu')(GenNetwork)\n    GenNetwork = Conv2D(512, kernel_size=5, strides=2, padding='same')(GenNetwork)\n    GenNetwork = BatchNormalization()(GenNetwork)\n    GenNetwork = Activation('relu')(GenNetwork)\n    GenNetwork = Conv2D(512, kernel_size=5, strides=2, padding='same')(GenNetwork)\n    GenNetwork = BatchNormalization()(GenNetwork)\n    GenNetwork = Activation('relu')(GenNetwork)\n    GenNetwork = Conv2D(512, kernel_size=5, strides=2, padding='same')(GenNetwork)\n    GenNetwork = BatchNormalization()(GenNetwork)\n    GenNetwork = Activation('relu')(GenNetwork)\n    GenNetwork = Flatten()(GenNetwork)\n    GenNetwork = Dense(1024, activation='relu')(GenNetwork)\n\n    x = concatenate([DisNetwork, GenNetwork])\n    x = Dense(1, activation='sigmoid')(x)\n    return Model(inputs=[g_img, inputLayer], outputs=x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "if __name__ == \"__main__\":\n    generator = Generative()\n    discriminator = Discriminative()\n\nclass Data(object):\n    def __init__(self, root_dir, imgSize, locSize):\n        self.locSize = locSize\n        self.imgSize = imgSize\n        self.reset()\n        self.fileList = []\n        for root, dirs, files in os.walk(root_dir):\n            for File in files:\n                imgPath = os.path.join(root, File)\n                if imghdr.what(imgPath) is None:\n                    continue\n                self.fileList.append(imgPath)\n    \n    def reset(self):\n        self.images = []\n        self.points = []\n        self.masks = []\n\n\n    def __len__(self):\n        return len(self.fileList)\n    \n    def flow(self, batchSize, minBlock=64, maxBlock=128):\n        np.random.shuffle(self.fileList)\n        for f in self.fileList:\n            i = cv2.imread(f)\n            i = cv2.resize(i, self.imgSize)[:, :, ::-1]\n            self.images.append(i)\n            \n            w, h = np.random.randint(minBlock, maxBlock, 2)\n            a1 = np.random.randint(0, self.imgSize[0] - self.locSize[0] + 1)\n            b1 = np.random.randint(0, self.imgSize[1] - self.locSize[1] + 1)\n            \n            a2,b2 = np.array([a1, b1]) + np.array(self.locSize)\n            self.points.append([a1, b1, a2, b2])\n\n            \n            p1 = a1 + np.random.randint(0, self.locSize[0] - w)\n            q1 = b1 + np.random.randint(0, self.locSize[1] - h)\n            p2 = p1 + w\n            q2 = q1 + h\n\n            m = np.zeros((self.imgSize[0], self.imgSize[1], 1), dtype=np.uint8)\n            m[q1:q2 + 1, p1:p2 + 1] = 1\n            self.masks.append(m)\n\n            if len(self.images) == batchSize:\n                inputs = np.asarray(self.images, dtype=np.float32) / 255\n                points = np.asarray(self.points, dtype=np.int32)\n                masks = np.asarray(self.masks, dtype=np.float32)\n                self.reset()\n                yield inputs, points, masks",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def GAN_Main(result_dir=\"output\", data_dir=\"data\"):\n    \n    alpha = 0.0004\n    input_shape = (256, 256, 3)\n    local_shape = (128, 128, 3)\n    \n    batchSize = 4\n    Epochs = 150\n    l1 = int(Epochs * 0.18)\n    l2 = int(Epochs * 0.02)\n    \n    train_datagen = Data(data_dir, input_shape[:2], local_shape[:2])\n\n    Gen = Generative(input_shape)\n    Dis = Discriminative(input_shape, local_shape)\n    \n    optimizer = Adadelta()\n#######\n    orgVal = Input(shape=input_shape)\n    mask = Input(shape=(input_shape[0], input_shape[1], 1))\n\n    imgContent = Lambda(lambda x:x[0]*(1 - x[1]), output_shape=input_shape)([orgVal, mask])\n    mimic = Gen(imgContent)\n    completion = Lambda(lambda x:x[0]*x[2]+x[1]*(1 - x[2]), output_shape=input_shape)([mimic, orgVal, mask])\n    Gen_container = Network([orgVal, mask], completion)\n    Gen_out = Gen_container([orgVal, mask])\n    Gen_model = Model([orgVal, mask], Gen_out)\n    Gen_model.compile(loss='mse', optimizer=optimizer)\n    \n    inputLayer = Input(shape=(4,), dtype='int32')\n    Dis_container = Network([orgVal, inputLayer], Dis([orgVal, inputLayer]))\n    Dis_model = Model([orgVal, inputLayer], Dis_container([orgVal, inputLayer]))\n    Dis_model.compile(loss='binary_crossentropy', optimizer=optimizer)\n    \n    Dis_container.trainable = False\n    totalModel = Model([orgVal, mask, inputLayer],\n                      [Gen_out, Dis_container([Gen_out, inputLayer])])\n    totalModel.compile(loss=['mse', 'binary_crossentropy'],\n                      loss_weights=[1.0, alpha], optimizer=optimizer)\n    \n    for n in range(Epochs):\n        progress = generic_utils.Progbar(len(train_datagen))\n        for inputs, points, masks in train_datagen.flow(batchSize):\n            Gen_image = Gen_model.predict([inputs, masks])\n            real = np.ones((batchSize, 1))\n            unreal = np.zeros((batchSize, 1))\n\n            generatorLoss = 0.0\n            discriminatorLoss = 0.0\n            \n            if n < l1:\n                generatorLoss = Gen_model.train_on_batch([inputs, masks], inputs)\n            else:\n                discriminatorLoss_real = Dis_model.train_on_batch([inputs, points], real)\n                discriminatorLoss_unreal = Dis_model.train_on_batch([Gen_image, points], unreal)\n                discriminatorLoss = 0.5 * np.add(discriminatorLoss_real, discriminatorLoss_unreal)\n                if n >= l1 + l2:\n                    generatorLoss = totalModel.train_on_batch([inputs, masks, points],[inputs, real])\n                    generatorLoss = generatorLoss[0] + alpha * generatorLoss[1]\n            progress.add(inputs.shape[0])\n        imgs = min(5,batchSize)\n        Display, Axis = mplt.subplots(imgs, 3)\n\n        Axis[0,0].set_title('Input Image')\n        Axis[0,1].set_title('Output Image')\n        Axis[0,2].set_title('Original Image')\n        \n        for i in range(imgs):\n            Axis[i,0].imshow(inputs[i]*(1-masks[i]))\n            Axis[i,0].axis('off')\n            Axis[i,1].imshow(Gen_image[i])\n            Axis[i,1].axis('off')\n            Axis[i,2].imshow(inputs[i])\n            Axis[i,2].axis('off')\n\n        Display.savefig(os.path.join(result_dir,\"Batch_%d.png\"% n))\n        mplt.close()\n\n#Trained Model Files...        \n    Gen.save(os.path.join(result_dir, \"generator.h5\"))\n    Dis.save(os.path.join(result_dir, \"discriminator.h5\"))",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def main():\n    GAN_Main()\n\nif __name__ == \"__main__\":\n    main()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}